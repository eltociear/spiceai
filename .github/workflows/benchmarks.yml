---
name: benchmark tests

on:
  workflow_dispatch:
    inputs:
      features:
        description: 'included features for bench'
        required: true
        default: "postgres,spark,mysql,odbc,delta_lake,databricks,duckdb"

jobs:
  setup-matrix:
    name: Setup strategy matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.setup-matrix.outputs.result }}

    steps:
      - name: Set up matrix
        uses: actions/github-script@v7
        id: setup-matrix
        with:
          script: |
            const matrix = "${{ inputs.features }}".split(',').map(f=>{
              return {
                feature: f
              }
            });

            return matrix;

  run-database-bench:
    name: Benchmark Tests
    runs-on: ubuntu-latest
    needs: setup-matrix
    strategy:
      matrix:
        target: ${{ fromJson(needs.setup-matrix.outputs.matrix) }}
    services:
      mysql:
        image: ${{ contains(matrix.target.feature, 'mysql') && 'ghcr.io/spiceai/spice-mysql-bench:latest' || '' }}
        options: >-
          --health-cmd="mysqladmin ping -uroot -proot --silent"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 3306:3306
        env:
          MYSQL_ROOT_PASSWORD: root
      postgres:
        image: ${{ contains(matrix.target.feature, 'postgres') && 'ghcr.io/spiceai/spice-postgres-bench:latest' || '' }}
        options: >-
          --health-cmd="pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
        env:
          POSTGRES_PASSWORD: postgres
    steps:
      - uses: actions/checkout@v4

      - name: Set up Rust
        uses: ./.github/actions/setup-rust
        with:
          os: 'linux'

      - name: Set up Spice.ai API Key
        run: |
          echo 'SPICEAI_API_KEY="${{ secrets.SPICE_SECRET_SPICEAI_BENCHMARK_KEY }}"' > .env

      - name: Install Protoc
        if: contains(matrix.target.feature, 'spark')
        uses: arduino/setup-protoc@v3
      
      - name: Install Databricks ODBC driver
        if: contains(matrix.target.feature, 'odbc')
        run: |
          sudo apt-get install unixodbc unixodbc-dev unzip libsasl2-modules-gssapi-mit -y
          wget https://databricks-bi-artifacts.s3.us-east-2.amazonaws.com/simbaspark-drivers/odbc/2.8.2/SimbaSparkODBC-2.8.2.1013-Debian-64bit.zip
          unzip SimbaSparkODBC-2.8.2.1013-Debian-64bit.zip
          sudo dpkg -i simbaspark_2.8.2.1013-2_amd64.deb
        
      - name: Install Athena ODBC driver
        if: contains(matrix.target.feature, 'odbc')
        run: |
          sudo apt-get install alien -y
          wget https://downloads.athena.us-east-1.amazonaws.com/drivers/ODBC/v2.0.3.0/Linux/AmazonAthenaODBC-2.0.3.0.rpm
          sudo alien -i AmazonAthenaODBC-2.0.3.0.rpm

      - run: cargo bench -p runtime --features ${{ matrix.target.feature }}
        env:
          UPLOAD_RESULTS_DATASET: 'spiceai.tests.oss_benchmarks'
          PG_BENCHMARK_PG_HOST: localhost
          PG_BENCHMARK_PG_USER: postgres
          PG_BENCHMARK_PG_PASS: postgres
          PG_BENCHMARK_PG_SSLMODE: disable
          PG_BENCHMARK_PG_DBNAME: tpch_sf0_01
          SPICE_SPARK_REMOTE: ${{ secrets.SPICE_SPARK_REMOTE }}
          MYSQL_BENCHMARK_MYSQL_HOST: localhost
          MYSQL_BENCHMARK_MYSQL_USER: root
          MYSQL_BENCHMARK_MYSQL_PASS: root
          MYSQL_BENCHMARK_MYSQL_DB: tpch_sf0_01
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_ODBC_PATH: ${{ secrets.DATABRICKS_ODBC_PATH }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          AWS_DATABRICKS_DELTA_ACCESS_KEY_ID: ${{ secrets.AWS_DATABRICKS_DELTA_ACCESS_KEY_ID }}
          AWS_DATABRICKS_DELTA_SECRET_ACCESS_KEY: ${{ secrets.AWS_DATABRICKS_DELTA_SECRET_ACCESS_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_S3_ATHENA_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_S3_ATHENA_SECRET_ACCESS_KEY }}
